**Grammars**

- Human and programming languages have specific (relevant) rules for grammar

**Step 1: Tokenization**

- A source code file is composed of tokens
- Each kind of token represents a specific kind of token that may legally exist in a program
  - Ex variable and function names, operators, etc.
- A compiler's first pass converts the text into tokens
- Language grammar restricts the valid ways a kind of token may be expressed
  - Ex. C++ variable names cannot begin with a number
- Compilation will fail if a program does not respect a language's token syntax
  - A good compiler will continue parsing to search for extra errors before the process finishes

**Step 2: Parsing**

- The compiler iterates through the tokens and tries to apply the rules of the language grammar
  - As the compiler scans the tokens, it builds an abstract synatax tree (AST) which represents the grammatical structure of the source code
    - Lecture slides have a great AST diagram
- If a token sequence cannot be mapped to a grammatical structure, compilation fails
- Once the AST is built, the compiler maps the AST to actual machine instructions

**Step 3: Code generation**

- The compiler associates each kind of AST subtree with rules for generating the appropriate CPU instructions
- To generate code, the compiler makes one or more traversals through the AST
- Example three phase compiler:
  1. If the developer requested optimizations, the initial passes look for opportunities to improve the AST (choose the fastest or minimum set of instructions that maintain semantic correctness)
  2. Determine which registers and memory areas will hold the values manipulated by the various parts of the AST
  3. Translate the entire AST to CPU instructions

**Optimization**

- _Generally_, given two sequences of instructions, the sequence with fewer instructions will execute faster
  - Ex: the compiler will reduce the number of instructions in arithmetic operations on constants when possible

**Many to many mappings between source code and cpu instructions**

- The same piece of source code can be mapped to many different sequences of machine instructions
  - Ex. An optmizing compiler may generate shorter sequences than a non optimizing compiler
  - Ex. A sanitizing compiler may add extra instructions to check for undefined behavior
  - Ex. A security-conscious compiler may add extra instructions to check for security problems
- The same sequence of machine instructions can also be mapped to multiple kinds of source code
  - A set of bytes in a register or in memory can be interpreted in different ways by high level languages
  - Semantically different pieces of source code might still perform the same instruction level operations

**Interpreters**

- Given an AST, a compiler generates CPU instructions that implement the semantics of the AST
- Given an AST, an interpreter executes the program directly

**Compilation v. Interpretation**

- Compile phase is faster with an interpreter
  - Interpreter has to translate source code and then execute it in an intermediate form
  - A compiler translates intermediate form to native CPU instructions
- Once a program has been compiled, the compiled version is almost always more performant than the interpreted version
